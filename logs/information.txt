Run at 2025-05-22 23:22:44.214192 
network = <repeaters.RepeaterNetwork object at 0x122405a90> 
n = 4 
lr = 0.0003 
gamma = 0.95 
epsilon = 0.2 
criterion = CrossEntropyLoss() 
weight_decay = 1e-05 
temperature = 1 
scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x1224056a0> 

 Model breakdown 
+-----------------------+----------------+----------------+----------+
| Layer                 | Input Shape    | Output Shape   | #Param   |
|-----------------------+----------------+----------------+----------|
| GNN                   | [4, 4]         | [4, 4]         | 2,780    |
| ├─(encoder)Sequential | --             | --             | 120      |
| │    └─(0)GATConv     | [4, 1], [2, 3] | [4, 8]         | 32       |
| │    └─(1)GATConv     | [4, 8], [2, 3] | [4, 8]         | 88       |
| ├─(latent)Sequential  | [4, 8]         | [4, 64]        | 2,400    |
| │    └─(0)Linear      | [4, 8]         | [4, 32]        | 288      |
| │    └─(1)ReLU        | [4, 32]        | [4, 32]        | --       |
| │    └─(2)Linear      | [4, 32]        | [4, 64]        | 2,112    |
| ├─(decoder)Sequential | [4, 64]        | [4, 4]         | 260      |
| │    └─(0)Linear      | [4, 64]        | [4, 4]         | 260      |
| │    └─(1)Softmax     | [4, 4]         | [4, 4]         | --       |
+-----------------------+----------------+----------------+----------+
Total params: 2,780

-Training information (Q-learning) 
 Trained for 21.932 sec performing 10000 steps.
trained, L=25, t_avg=39.6, t_std=25.2
random, L=11, t_avg=90.5, t_std=109.3
swapASAP, L=83, t_avg=12.0, t_std=7.5
alternating, L=17, t_avg=54.5, t_std=38.8
