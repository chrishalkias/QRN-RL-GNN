--------------------------------------------------

 >>> Total links established : 83

 >>> Avg transfer time       : 11.988 it 

 >>>Typical time deviation   : 7.489 it
--------------------------------------------------
Action reward log for swapASAP at 2025-05-22 23:23:08.109419


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0.0, 0, 0.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 11 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [0.0, 1, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: 1
 State: [1, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 10 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 12 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 13 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 17 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [0.0, 1, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: 1
 State: [1, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 1, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: 1
 State: [0.0, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 14 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 3 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 20 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 16 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 13 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [0.0, 1, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: 1
 State: [0.0, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 12 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 15 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 9 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 17 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 9 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 1, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [0.0, 1, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: 1
 State: [0.0, 1, 1.0, 1, 0.0, 0.0]



--Linked in 25 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 13 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 9 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [0, 1, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: 1
 State: [0.0, 1, 1.0, 1, 0.0, 0.0]



--Linked in 16 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 11 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 19 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [0.0, 1, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: 1
 State: [0.0, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 29 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 12 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 12 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 21 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 17 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 9 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [0, 1, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: 1
 State: [0.0, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 17 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 11 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 14 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 12 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 11 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 12 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0, 1.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 18 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 13 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 1, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: 1
 State: [0.0, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 42 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 1, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: 1
 State: [0.0, 1, 1.0, 1, 0.0, 0.0]



--Linked in 35 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [0.0, 1, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: 1
 State: [1, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 10 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 16 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 11 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 25 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 3 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 16 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 1, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [0, 1, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: 1
 State: [0.0, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 39 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 1, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: 1
 State: [0.0, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [0.0, 1, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: 1
 State: [1, 1, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 16 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 12 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 16 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 16 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 14 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 16 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [1, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0.0, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [1, 0.0, 0.0, 0, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 10 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [0, 1, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.07500000000000001
 State: [1, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: 1
 State: [0.0, 1, 1.0, 1, 0.0, 0.0]



--Linked in 10 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08750000000000001
 State: [1, 0, 0, 1, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [1, 1, 0, 1, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.09375
 State: [0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08750000000000001
 State: [1, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.08125
 State: [0.0, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 1, 1.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))'],Reward: -0.06875
 State: [1, 1, 0.0, 1, 1.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)'],Reward: 1
 State: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 13 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))'],Reward: -0.1
 State: [0, 0, 0, 0, 0, 0]

