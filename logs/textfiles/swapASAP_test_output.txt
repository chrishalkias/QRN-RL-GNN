--------------------------------------------------

 >>> Total links established : 165

 >>> Avg transfer time       : 6.048 it 

 >>>Typical time deviation   : 7.994 it
--------------------------------------------------
Action reward log for swapASAP at 2025-05-22 19:58:43.770193


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 11 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 0.0, 0.0, 0, 0, 1, 0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 16 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 10 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 3 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 18 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 11 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.06944444444444445
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 1, 0.0, 0.0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 1.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 1.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 19 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08888888888888889
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [1, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 1.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: -0.09166666666666667
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 1.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 46 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [1, 0, 0.0, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 9 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 11 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0, 0.0, 0, 1, 1.0, 1, 0.0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 10 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0, 0.0, 0, 1, 1.0, 1, 0.0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [1, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [1, 1.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 1.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 43 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 1.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 14 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 23 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 30 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08333333333333334
 State: [0.0, 1.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 11 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 1.0, 1, 0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08888888888888889
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 1.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 0.0, 0.0, 0, 0, 1, 0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [0.0, 1.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 25 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.06944444444444445
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 1.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 30 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 17 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08888888888888889
 State: [0.0, 0, 0.0, 0.0, 0, 0, 0.0, 0, 1, 1.0, 1, 0.0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [1, 0, 1, 0.0, 1, 0, 0.0, 0, 1, 1.0, 1, 0.0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0, 0.0, 0, 1, 1.0, 1, 0.0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [0.0, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 1.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [0.0, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: -0.09166666666666667
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 9 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.06944444444444445
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08888888888888889
 State: [0.0, 0, 0.0, 0.0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08333333333333334
 State: [1, 0, 1, 0.0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 12 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 3 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [1, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 1.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: -0.09166666666666667
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 54 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 3 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.06944444444444445
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0, 0.0, 0, 1, 1.0, 1, 0.0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 7 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 13 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 13 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 10 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 14 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08888888888888889
 State: [0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 1, 0.0, 0.0, 0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 5 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 4 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 1, 0.0, 0.0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 1.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.06944444444444445
 State: [1, 0.0, 1, 0.0, 1, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.06944444444444445
 State: [1, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 32 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0, 0.0, 0, 1, 1.0, 1, 0.0, 0, 0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'entangle(edge=(4, 5))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 1.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))'],Reward: -0.08333333333333334
 State: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07500000000000001
 State: [1, 1.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: -0.09166666666666667
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [1, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 0.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 13 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 0.0, 0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 8 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08611111111111111
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0, 0.0, 0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07500000000000001
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.07777777777777778
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 1.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0, 1, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 0.0, 0.0, 1.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08055555555555556
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0.0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 15 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08055555555555556
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(3, 4))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 17 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08888888888888889
 State: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['entangle(edge=(1, 2))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08611111111111111
 State: [1, 0.0, 1, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07777777777777778
 State: [0.0, 0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'swapAT(3)', 'swapAT(4)'],Reward: -0.08333333333333334
 State: [0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0, 0.0]


 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(2, 3))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.07222222222222223
 State: [1, 0.0, 1, 0.0, 1, 0.0, 0.0, 0.0, 1, 1.0, 1, 0.0, 1.0, 0, 0.0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 6 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.08611111111111111
 State: [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]


 Action: ['swapAT(1)', 'swapAT(2)', 'swapAT(3)', 'swapAT(4)'],Reward: 1
 State: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]



--Linked in 2 steps for swapASAP 

 Action: ['entangle(edge=(0, 1))', 'entangle(edge=(0, 1))', 'entangle(edge=(1, 2))', 'entangle(edge=(2, 3))', 'entangle(edge=(3, 4))', 'entangle(edge=(4, 5))'],Reward: -0.09166666666666667
 State: [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]

