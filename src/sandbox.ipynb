{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b729555",
   "metadata": {},
   "source": [
    "# Sandbox for QRN-RL-GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79009a53",
   "metadata": {},
   "source": [
    "This is an IPython notebook to be used for the following:\n",
    "\n",
    "1) As a sandbox to test snippets of code during development\n",
    "\n",
    "2) For demonstration purposes of functionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246cc87",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a432bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from repeaters import RepeaterNetwork\n",
    "from models import CNN, GNN\n",
    "from gnn_env import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08419f27",
   "metadata": {},
   "source": [
    "# Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef4f65",
   "metadata": {},
   "source": [
    "Below is a set of examples on some basic functionality of the code to make it more apparent how the code connect to the physical system () at least in a high level way. This is Basic usage 1. On Basic usage 2 the container of the environment for the RL agent is showcased. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5492dc",
   "metadata": {},
   "source": [
    "## Basic usage 1: The Quantum repeaters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b01f55",
   "metadata": {},
   "source": [
    "First lets initialize the network this is done with the `RepeaterNetwork` class. It is parametrized by the number of nodes $n$, the system parameters $\\tau, p_e, p_s$ and some other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "17177a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RepeaterNetwork(\n",
    "                    n=4,\n",
    "                    p_entangle = 1,\n",
    "                    p_swap = 1,\n",
    "                    tau = 1_000,\n",
    "                    kappa = 1,\n",
    "                    directed = False,\n",
    "                    geometry = 'chain',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf0ca6",
   "metadata": {},
   "source": [
    "The state can be seen anytime with ```self.matrix``` (dictionary) or used gor GNNs with ```self.tensorState()``` (pyG.data). For the first case the state is returned in a dictionary of the form $\\texttt{self.matrix} = \\big\\{(i,j) : [\\text{adj}, \\text{ent}]\\big\\}$ where $i,j$ denote the vertices (repeaters) of the edge (links), adj denotes the adjecency (0,1) and ent the links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f89dad8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): [1, 0.0],\n",
       " (1, 2): [1, 0.0],\n",
       " (0, 3): [0.0, 0.0],\n",
       " (2, 3): [1, 0.0],\n",
       " (0, 2): [0.0, 0.0],\n",
       " (1, 3): [0.0, 0.0]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "294d93f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# internal variable controls end-to-end\n",
    "net.global_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937410a8",
   "metadata": {},
   "source": [
    "### Operation 1: Entanglement\n",
    "\n",
    "This is what establishes the local links to be extended to reach end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c09c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_for_entanglement(edge):\n",
    "    print(f'Entanglement at {edge}: {net.getLink(edge=(0,1), linkType = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c7255ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entanglement at (0, 1): 0.0\n",
      "Entanglement at (0, 1): 1\n"
     ]
    }
   ],
   "source": [
    "edge = (0,1)\n",
    "look_for_entanglement(edge=edge)\n",
    "net.entangle(edge = (0,1))\n",
    "look_for_entanglement(edge=edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab6aba60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): [1, 0],\n",
       " (1, 2): [1, 0],\n",
       " (0, 3): [0.0, 0],\n",
       " (2, 3): [1, 0],\n",
       " (0, 2): [0.0, 0],\n",
       " (1, 3): [0.0, 0]}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets reset\n",
    "net.resetState()\n",
    "net.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d5995",
   "metadata": {},
   "source": [
    "### Operation 2: Swap\n",
    "\n",
    "The second operation is performing a swap by \"merging\" the entanglement values of two edges into one. The rule is that the two edges need to share a repeater. This is what effectivelly extends the links to greater than nearest neighbour distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "43858484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initial entanglement :0\n",
      " Final entanglement : 1.000\n"
     ]
    }
   ],
   "source": [
    "#two entanglements and a swap give an extended link\n",
    "print(f' Initial entanglement :{net.matrix[(0,2)][1]}')\n",
    "net.entangle(edge=(0,1))\n",
    "net.entangle(edge=(1,2))\n",
    "net.swapAT(1)\n",
    "print(f' Final entanglement : {net.matrix[(0,2)][1]:.3f}')\n",
    "net.resetState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bce618e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initial entanglement :0\n",
      " Final entanglement :0.0\n"
     ]
    }
   ],
   "source": [
    "# can also be done with an edge specific swap function\n",
    "print(f' Initial entanglement :{net.matrix[(0,2)][1]}')\n",
    "net.entangle(edge=(0,1))\n",
    "net.entangle(edge=(1,2))\n",
    "net.swap(edge1=(0,1), edge2=(1,2))\n",
    "print(f' Final entanglement :{net.matrix[(0,2)][1]}')\n",
    "net.resetState()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302af25a",
   "metadata": {},
   "source": [
    "### Operation 3: Ageing\n",
    "\n",
    "Yes even quantum networks age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c1d6ae01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): [1, 0.3660446348040154],\n",
       " (1, 2): [1, 0.3664108625221595],\n",
       " (0, 3): [0.0, 0.0],\n",
       " (2, 3): [1, 0.36714441755772104],\n",
       " (0, 2): [0.0, 0.0],\n",
       " (1, 3): [0.0, 0.0]}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#links age with half life net.tau\n",
    "[net.entangle(edge=edge) for edge in net.matrix.keys()]\n",
    "net.tick(T = net.tau)\n",
    "net.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdec31",
   "metadata": {},
   "source": [
    "## Basic Usage 2: The Environment\n",
    "\n",
    "This is a container for `net` where a model based RL algorithm acts on the system using a neural network as its environment model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d743f5",
   "metadata": {},
   "source": [
    "### Setup:\n",
    "\n",
    "Here lets create some configuration files. The first one is for the quantum repeater network ,Here we specify the type of network that we want to use. The number of nodes for training and testing can be different. Afterwards we do the same for the agent. Keep in mind here that the hyper parameters have not been optimized with some HPO procedure and therefore results of training may vary wildly depending on the HP and the (stochastic) initialization used to run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now start using config files, first for the network\n",
    "sys_config = {\n",
    "    'n_train'        : 4,\n",
    "    'n_test'         : 4,\n",
    "    'tau'            : 50_000,\n",
    "    'p_entangle'     : .85,\n",
    "    'p_swap'         : .85,\n",
    "    'kappa'          : 1, # Global depolarizer, legacy code\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89828853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then for the environment\n",
    "agent_config = {\n",
    "    'train_agent'    : True,\n",
    "    'train_steps'    : 50_000,\n",
    "    'learning_rate'  : 0.005,\n",
    "    'weight_decay'   : 1e-4,\n",
    "    'temperature'    : .8,\n",
    "    'gamma'          : 0.9,\n",
    "    'epsilon'        : 0.1,\n",
    "    'plot_metrics'   : True,\n",
    "    'plot_loss'      : True,\n",
    "    'print_model'    : True,\n",
    "    'evaluate_agent' : True,\n",
    "    'test_steps'     : 1_000,\n",
    "    'render_eval'    : True,   \n",
    "    }         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "99f1a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and lastly for the model used\n",
    "model_config = {\n",
    "    'input_features' : 1, # always\n",
    "    'embedding_dim'  : 8,\n",
    "    'num_layers'     : 3,\n",
    "    'num_heads'      : 2,\n",
    "    'hidden_dim'     : 64, \n",
    "    'unembedding_dim': 32, \n",
    "    'output_dim'     : 4, # always\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86634b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now create instances of the model and Environment\n",
    "model = GNN(\n",
    "        node_dim          = model_config['input_features'], \n",
    "        embedding_dim     = model_config['embedding_dim'],\n",
    "        num_layers        = model_config['num_layers'],\n",
    "        num_heads         = model_config['num_heads'],\n",
    "        hidden_dim        = model_config['hidden_dim'], \n",
    "        unembedding_dim   = model_config['unembedding_dim'], \n",
    "        output_dim        = model_config['output_dim'], \n",
    "        ) \n",
    "\n",
    "exp = Environment(\n",
    "            model        = model,\n",
    "            n            = sys_config['n_train'],\n",
    "            kappa        = sys_config['kappa'],\n",
    "            tau          = sys_config['tau'],\n",
    "            p_entangle   = sys_config['p_entangle'], \n",
    "            p_swap       = sys_config['p_swap'],\n",
    "            lr           = agent_config['learning_rate'], \n",
    "            weight_decay = agent_config['weight_decay'],\n",
    "            gamma        = agent_config['gamma'], \n",
    "            epsilon      = agent_config['epsilon'],\n",
    "            temperature  = agent_config['temperature']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540053bd",
   "metadata": {},
   "source": [
    "### Training:\n",
    "The agent can be trained by an internal method and will output the metrics on a logs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8866c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if agent_config['train_agent']:\n",
    "#         exp.trainQ(episodes=agent_config['train_steps'], plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb78447",
   "metadata": {},
   "source": [
    "### Testing:\n",
    "\n",
    "The agent can be avaluated, either on the same system or on a never seen network with different parameters and output evaluation logs in the same destination as the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if agent_config['evaluate_agent']:\n",
    "#         for kind in ['trained', 'random', 'alternating']:\n",
    "#             exp.test(n_test=sys_config['n_test'], \n",
    "#                         max_steps=agent_config['test_steps'], \n",
    "#                         kind=kind, \n",
    "#                         plot=agent_config['render_eval'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
